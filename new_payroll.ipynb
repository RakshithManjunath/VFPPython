{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023-09-01']\n",
      "['2023-09-02']\n",
      "['2023-09-04']\n",
      "['2023-09-05']\n",
      "['2023-09-06']\n",
      "['2023-09-07']\n",
      "['2023-09-08']\n",
      "['2023-09-09']\n",
      "['2023-09-11']\n",
      "['2023-09-12']\n",
      "['2023-09-13']\n",
      "['2023-09-14']\n",
      "['2023-09-15']\n",
      "['2023-09-16']\n",
      "['2023-09-18']\n",
      "['2023-09-19']\n",
      "['2023-09-20']\n",
      "['2023-09-21']\n",
      "['2023-09-22']\n",
      "['2023-09-23']\n",
      "['2023-09-25']\n",
      "['2023-09-26']\n",
      "['2023-09-27']\n",
      "['2023-09-28']\n",
      "['2023-09-29']\n",
      "['2023-09-30']\n",
      "['2023-09-03']\n"
     ]
    }
   ],
   "source": [
    "from dbfread import DBF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "punches_table = DBF('D:/ZIONtest/punches.dbf', load=True)\n",
    "punches_df = pd.DataFrame(iter(punches_table))\n",
    "punches_df = punches_df.sort_values(by=['TOKEN', 'PDATE', 'MODE'])\n",
    "\n",
    "punches_df['PDTIME'] = pd.to_datetime(punches_df['PDTIME'], format='%d-%b-%y %H:%M:%S')\n",
    "\n",
    "punches_df.sort_values(by=['TOKEN', 'PDTIME', 'MODE'], inplace=True)\n",
    "\n",
    "result_df = pd.DataFrame(columns=['TOKEN', 'PDATE', 'INTIME', 'OUTTIME', 'TOTALTIME'])\n",
    "\n",
    "in_punch_time = None\n",
    "out_punch_time = None\n",
    "\n",
    "for index, row in punches_df.iterrows():\n",
    "    if row['MODE'] == 0:\n",
    "        in_punch_time = row['PDTIME']\n",
    "    elif row['MODE'] == 1:\n",
    "        out_punch_time = row['PDTIME']\n",
    "        if in_punch_time is not None:\n",
    "            time_difference = out_punch_time - in_punch_time\n",
    "            if time_difference.total_seconds() > 0:\n",
    "                hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "                minutes, seconds = divmod(remainder, 60)\n",
    "                pdate = [pd.to_datetime(in_punch_time, format='%d-%b-%y %H:%M:%S').strftime('%Y-%m-%d')]\n",
    "                pdate_datetime = pd.to_datetime(pdate)\n",
    "                if pdate_datetime.isin(result_df['PDATE']).any():\n",
    "                    print(\"Date exists\")\n",
    "                else:\n",
    "\n",
    "                    result_df = pd.concat([result_df, pd.DataFrame({\n",
    "                        'TOKEN': [row['TOKEN']],\n",
    "                        'INTIME': [in_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                        'OUTTIME': [out_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                        'PDATE': pdate,\n",
    "                        'TOTALTIME': [f'{hours:02}:{minutes:02}:{seconds:02}']\n",
    "                    })], ignore_index=True)\n",
    "\n",
    "result_df = result_df.sort_values(by=['TOKEN', 'PDATE'])\n",
    "\n",
    "result_df.to_csv('./5thJan_punches.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows found based on 'PDATE' and 'TOKEN':\n",
      "   TOKEN      PDATE               INTIME              OUTTIME TOTALTIME\n",
      "29     2 2023-09-03  2023-09-03 16:00:59  2023-09-04 02:01:00  10:00:00\n",
      "31     2 2023-09-04  2023-09-04 18:00:00  2023-09-05 05:00:00  11:00:00\n",
      "33     2 2023-09-05  2023-09-05 23:01:00  2023-09-06 04:00:59  04:59:59\n"
     ]
    }
   ],
   "source": [
    "from dbfread import DBF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "punches_table = DBF('D:/ZIONtest/punches.dbf', load=True)\n",
    "punches_df = pd.DataFrame(iter(punches_table))\n",
    "punches_df = punches_df.sort_values(by=['TOKEN', 'PDATE', 'MODE'])\n",
    "\n",
    "punches_df['PDTIME'] = pd.to_datetime(punches_df['PDTIME'], format='%d-%b-%y %H:%M:%S')\n",
    "\n",
    "punches_df.sort_values(by=['TOKEN', 'PDTIME', 'MODE'], inplace=True)\n",
    "\n",
    "result_df = pd.DataFrame(columns=['TOKEN', 'PDATE', 'INTIME', 'OUTTIME'])\n",
    "\n",
    "in_punch_time = None\n",
    "out_punch_time = None\n",
    "\n",
    "for index, row in punches_df.iterrows():\n",
    "    if row['MODE'] == 0:\n",
    "        in_punch_time = row['PDTIME']\n",
    "    elif row['MODE'] == 1:\n",
    "        out_punch_time = row['PDTIME']\n",
    "        if in_punch_time is not None:\n",
    "            time_difference = out_punch_time - in_punch_time\n",
    "            if time_difference.total_seconds() > 0:\n",
    "                hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "                minutes, seconds = divmod(remainder, 60)\n",
    "                result_df = pd.concat([result_df, pd.DataFrame({\n",
    "                    'TOKEN': [row['TOKEN']],\n",
    "                    'INTIME': [in_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                    'OUTTIME': [out_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                    'PDATE': [pd.to_datetime(in_punch_time, format='%d-%b-%y %H:%M:%S').strftime('%Y-%m-%d')]\n",
    "                })], ignore_index=True)\n",
    "\n",
    "result_df = result_df.sort_values(by=['TOKEN', 'PDATE'])\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming result_df['PDATE'] and result_df['TOKEN'] are columns of interest\n",
    "result_df['PDATE'] = pd.to_datetime(result_df['PDATE'])\n",
    "\n",
    "# List of columns to check for duplicates\n",
    "columns_to_check = ['PDATE', 'TOKEN']\n",
    "\n",
    "# Check for duplicate rows based on 'PDATE' and 'TOKEN'\n",
    "duplicate_rows = result_df[result_df.duplicated(columns_to_check)]\n",
    "\n",
    "if not duplicate_rows.empty:\n",
    "    print(\"Duplicate rows found based on 'PDATE' and 'TOKEN':\")\n",
    "    print(duplicate_rows)\n",
    "else:\n",
    "    print(\"No duplicate rows found based on 'PDATE' and 'TOKEN'\")\n",
    "\n",
    "\n",
    "result_df.to_csv('./5thJan_punches.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "import numpy as np\n",
    "\n",
    "muster_table = DBF('D:/ZIONtest/muster.dbf', load=True)\n",
    "muster_df = pd.DataFrame(iter(muster_table))\n",
    "\n",
    "muster_df = muster_df[['TOKEN', 'COMCODE', 'NAME', 'EMPCODE', \n",
    "                         'EMP_DEPT','DEPT_NAME', 'EMP_DESI',\n",
    "                         'DESI_NAME']]\n",
    "muster_df = muster_df.sort_values(by=['EMPCODE'])\n",
    "\n",
    "punches_table = DBF('D:/ZIONtest/punches.dbf', load=True)\n",
    "punches_df = pd.DataFrame(iter(punches_table))\n",
    "punches_df = punches_df.sort_values(by=['TOKEN', 'PDATE', 'MODE'])\n",
    "\n",
    "punches_df['PDTIME'] = pd.to_datetime(punches_df['PDTIME'], format='%d-%b-%y %H:%M:%S')\n",
    "\n",
    "punches_df.sort_values(by=['TOKEN', 'PDTIME', 'MODE'], inplace=True)\n",
    "\n",
    "result_df = pd.DataFrame(columns=['TOKEN', 'PDATE', 'INTIME', 'OUTTIME', 'INTIME1', 'OUTTIME1', 'TOTALTIME'])\n",
    "\n",
    "in_punch_time = None\n",
    "out_punch_time = None\n",
    "\n",
    "for index, row in punches_df.iterrows():\n",
    "    if row['MODE'] == 0:\n",
    "        in_punch_time = row['PDTIME']\n",
    "    elif row['MODE'] == 1:\n",
    "        out_punch_time = row['PDTIME']\n",
    "        if in_punch_time is not None:\n",
    "            time_difference = out_punch_time - in_punch_time\n",
    "            if time_difference.total_seconds() > 0:\n",
    "                hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "                minutes, seconds = divmod(remainder, 60)\n",
    "                \n",
    "                # Check for duplicates based on 'PDATE' and 'TOKEN'\n",
    "                duplicates = result_df[(result_df['PDATE'] == in_punch_time.strftime('%Y-%m-%d')) & (result_df['TOKEN'] == row['TOKEN'])]\n",
    "                \n",
    "                if duplicates.empty:\n",
    "                    # No duplicates, add a new row\n",
    "                    result_df = pd.concat([result_df, pd.DataFrame({\n",
    "                        'TOKEN': [row['TOKEN']],\n",
    "                        'INTIME': [in_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                        'OUTTIME': [out_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                        'PDATE': [in_punch_time.strftime('%Y-%m-%d')],\n",
    "                        'INTIME1': [np.nan],\n",
    "                        'OUTTIME1': [np.nan],\n",
    "                        'TOTALTIME': [f'{hours:02}:{minutes:02}:{seconds:02}']\n",
    "                    })], ignore_index=True)\n",
    "                else:\n",
    "                    # Duplicates found, update the existing row\n",
    "                    result_df.loc[duplicates.index[-1], 'INTIME1'] = in_punch_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    result_df.loc[duplicates.index[-1], 'OUTTIME1'] = out_punch_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    \n",
    "                    # Calculate TOTALTIME based on the sum of time differences for both pairs\n",
    "                    total_time_difference_1 = pd.to_datetime(result_df.loc[duplicates.index[-1], 'OUTTIME']) - pd.to_datetime(result_df.loc[duplicates.index[-1], 'INTIME'])\n",
    "                    total_time_difference_2 = pd.to_datetime(result_df.loc[duplicates.index[-1], 'OUTTIME1']) - pd.to_datetime(result_df.loc[duplicates.index[-1], 'INTIME1'])\n",
    "                    \n",
    "                    total_hours_1, total_remainder_1 = divmod(total_time_difference_1.seconds, 3600)\n",
    "                    total_minutes_1, total_seconds_1 = divmod(total_remainder_1, 60)\n",
    "                    \n",
    "                    total_hours_2, total_remainder_2 = divmod(total_time_difference_2.seconds, 3600)\n",
    "                    total_minutes_2, total_seconds_2 = divmod(total_remainder_2, 60)\n",
    "                    \n",
    "                    total_hours = total_hours_1 + total_hours_2\n",
    "                    total_minutes = total_minutes_1 + total_minutes_2\n",
    "                    total_seconds = total_seconds_1 + total_seconds_2\n",
    "                    \n",
    "                    result_df.loc[duplicates.index[-1], 'TOTALTIME'] = f'{total_hours:02}:{total_minutes:02}:{total_seconds:02}'\n",
    "\n",
    "result_df = result_df.sort_values(by=['TOKEN', 'PDATE'])\n",
    "\n",
    "\n",
    "final_merged_df = pd.merge(muster_df, result_df, on='TOKEN', how='left')\n",
    "final_merged_df = final_merged_df.sort_values(by=['EMPCODE', 'TOKEN', 'PDATE'])\n",
    "final_merged_df.to_csv('./final.csv', index=False)\n",
    "\n",
    "\n",
    "# result_df.to_csv('./6thJan_punches_modified.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "import numpy as np\n",
    "\n",
    "muster_table = DBF('D:/ZIONtest/muster.dbf', load=True)\n",
    "muster_df = pd.DataFrame(iter(muster_table))\n",
    "\n",
    "muster_df = muster_df[['TOKEN', 'COMCODE', 'NAME', 'EMPCODE', \n",
    "                         'EMP_DEPT','DEPT_NAME', 'EMP_DESI',\n",
    "                         'DESI_NAME']]\n",
    "muster_df = muster_df.sort_values(by=['EMPCODE'])\n",
    "\n",
    "punches_table = DBF('D:/ZIONtest/punches.dbf', load=True)\n",
    "punches_df = pd.DataFrame(iter(punches_table))\n",
    "punches_df = punches_df.sort_values(by=['TOKEN', 'PDATE', 'MODE'])\n",
    "\n",
    "punches_df['PDTIME'] = pd.to_datetime(punches_df['PDTIME'], format='%d-%b-%y %H:%M:%S')\n",
    "\n",
    "punches_df.sort_values(by=['TOKEN', 'PDTIME', 'MODE'], inplace=True)\n",
    "\n",
    "result_df = pd.DataFrame(columns=['TOKEN', 'PDATE', 'INTIME', 'OUTTIME', 'TOTALTIME', 'INTIME1'])\n",
    "\n",
    "in_punch_time = None\n",
    "out_punch_time = None\n",
    "\n",
    "for index, row in punches_df.iterrows():\n",
    "    if row['MODE'] == 0:\n",
    "        in_punch_time = row['PDTIME']\n",
    "    elif row['MODE'] == 1:\n",
    "        out_punch_time = row['PDTIME']\n",
    "        if in_punch_time is not None:\n",
    "            time_difference = out_punch_time - in_punch_time\n",
    "            if time_difference.total_seconds() > 0:\n",
    "                hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "                minutes, seconds = divmod(remainder, 60)\n",
    "                \n",
    "                # Check for duplicates based on 'PDATE' and 'TOKEN'\n",
    "                duplicates = result_df[(result_df['PDATE'] == in_punch_time.strftime('%Y-%m-%d')) & (result_df['TOKEN'] == row['TOKEN'])]\n",
    "                \n",
    "                if duplicates.empty:\n",
    "                    # No duplicates, add a new row\n",
    "                    result_df = pd.concat([result_df, pd.DataFrame({\n",
    "                        'TOKEN': [row['TOKEN']],\n",
    "                        'INTIME': [in_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                        'OUTTIME': [out_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                        'PDATE': [in_punch_time.strftime('%Y-%m-%d')],\n",
    "                        'TOTALTIME': [f'{hours:02}:{minutes:02}:{seconds:02}'],\n",
    "                        'INTIME1': [np.nan]\n",
    "                    })], ignore_index=True)\n",
    "                else:\n",
    "                    # Duplicates found, update the existing row\n",
    "                    result_df.loc[duplicates.index[-1], 'OUTTIME'] = out_punch_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    \n",
    "                    # Calculate TOTALTIME based on the sum of time differences for both pairs\n",
    "                    total_time_difference_1 = pd.to_datetime(result_df.loc[duplicates.index[-1], 'OUTTIME']) - pd.to_datetime(result_df.loc[duplicates.index[-1], 'INTIME'])\n",
    "                    \n",
    "                    total_hours_1, total_remainder_1 = divmod(total_time_difference_1.seconds, 3600)\n",
    "                    total_minutes_1, total_seconds_1 = divmod(total_remainder_1, 60)\n",
    "                    \n",
    "                    total_hours = total_hours_1\n",
    "                    total_minutes = total_minutes_1\n",
    "                    total_seconds = total_seconds_1\n",
    "                    \n",
    "                    result_df.loc[duplicates.index[-1], 'TOTALTIME'] = f'{total_hours:02}:{total_minutes:02}:{total_seconds:02}'\n",
    "\n",
    "# Drop 'INTIME1' if it was added\n",
    "if 'INTIME1' in result_df.columns:\n",
    "    result_df = result_df.drop(columns=['INTIME1'])\n",
    "\n",
    "result_df = result_df.sort_values(by=['TOKEN', 'PDATE'])\n",
    "result_df.to_csv('./6thJan_punches_modified.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "import numpy as np\n",
    "\n",
    "# Load and process muster data\n",
    "muster_table = DBF('D:/ZIONtest/muster.dbf', load=True)\n",
    "muster_df = pd.DataFrame(iter(muster_table))\n",
    "muster_df = muster_df[['TOKEN', 'COMCODE', 'NAME', 'EMPCODE', 'EMP_DEPT', 'DEPT_NAME', 'EMP_DESI', 'DESI_NAME']]\n",
    "muster_df = muster_df.sort_values(by=['EMPCODE'])\n",
    "\n",
    "# Load and process punches data\n",
    "punches_table = DBF('D:/ZIONtest/punches.dbf', load=True)\n",
    "punches_df = pd.DataFrame(iter(punches_table))\n",
    "punches_df = punches_df.sort_values(by=['TOKEN', 'PDATE', 'MODE'])\n",
    "\n",
    "# Make seconds part '00' in PDTIME\n",
    "punches_df['PDTIME'] = pd.to_datetime(punches_df['PDTIME'], format='%d-%b-%y %H:%M:%S').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Sort punches_df based on TOKEN, PDTIME, MODE\n",
    "punches_df.sort_values(by=['TOKEN', 'PDTIME', 'MODE'], inplace=True)\n",
    "\n",
    "# Initialize result DataFrame\n",
    "result_df = pd.DataFrame(columns=['TOKEN', 'PDATE', 'INTIME', 'OUTTIME', 'INTIME1', 'OUTTIME1'])\n",
    "\n",
    "in_punch_time = None\n",
    "out_punch_time = None\n",
    "\n",
    "# Iterate through punches_df to process punch data\n",
    "for index, row in punches_df.iterrows():\n",
    "    if row['MODE'] == 0:\n",
    "        in_punch_time = pd.to_datetime(row['PDTIME']).replace(second=0)\n",
    "    elif row['MODE'] == 1:\n",
    "        out_punch_time = pd.to_datetime(row['PDTIME']).replace(second=0)\n",
    "        if in_punch_time is not None:\n",
    "            time_difference = out_punch_time - in_punch_time\n",
    "            if time_difference.total_seconds() > 0:\n",
    "                hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "                minutes, seconds = divmod(remainder, 60)\n",
    "                \n",
    "                # Check for duplicates based on 'PDATE' and 'TOKEN'\n",
    "                duplicates = result_df[(result_df['PDATE'] == in_punch_time.strftime('%Y-%m-%d')) & (result_df['TOKEN'] == row['TOKEN'])]\n",
    "                \n",
    "                if duplicates.empty:\n",
    "                    # No duplicates, add a new row\n",
    "                    result_df = pd.concat([result_df, pd.DataFrame({\n",
    "                        'TOKEN': [row['TOKEN']],\n",
    "                        'INTIME': [in_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                        'OUTTIME': [out_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                        'PDATE': [in_punch_time.strftime('%Y-%m-%d')],\n",
    "                        'INTIME1': [np.nan],\n",
    "                        'OUTTIME1': [np.nan]\n",
    "                    })], ignore_index=True)\n",
    "                else:\n",
    "                    # Duplicates found, update the existing row\n",
    "                    result_df.loc[duplicates.index[-1], 'INTIME1'] = in_punch_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    result_df.loc[duplicates.index[-1], 'OUTTIME1'] = out_punch_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    \n",
    "                    # Calculate TOTALTIME based on the sum of time differences for both pairs\n",
    "                    total_time_difference_1 = pd.to_datetime(result_df.loc[duplicates.index[-1], 'OUTTIME']) - pd.to_datetime(result_df.loc[duplicates.index[-1], 'INTIME'])\n",
    "                    total_time_difference_2 = pd.to_datetime(result_df.loc[duplicates.index[-1], 'OUTTIME1']) - pd.to_datetime(result_df.loc[duplicates.index[-1], 'INTIME1'])\n",
    "                    \n",
    "\n",
    "# Sort result_df based on TOKEN, PDATE\n",
    "result_df = result_df.sort_values(by=['TOKEN', 'PDATE'])\n",
    "\n",
    "# Save the result to a CSV file\n",
    "result_df.to_csv('./6thJan_punches_modified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "import numpy as np\n",
    "\n",
    "# Load and process muster data\n",
    "muster_table = DBF('D:/ZIONtest/muster.dbf', load=True)\n",
    "muster_df = pd.DataFrame(iter(muster_table))\n",
    "muster_df = muster_df[['TOKEN', 'COMCODE', 'NAME', 'EMPCODE', 'EMP_DEPT', 'DEPT_NAME', 'EMP_DESI', 'DESI_NAME']]\n",
    "muster_df = muster_df.sort_values(by=['EMPCODE'])\n",
    "\n",
    "# Load and process punches data\n",
    "punches_table = DBF('D:/ZIONtest/punches.dbf', load=True)\n",
    "punches_df = pd.DataFrame(iter(punches_table))\n",
    "punches_df = punches_df.sort_values(by=['TOKEN', 'PDATE', 'MODE'])\n",
    "\n",
    "# Make seconds part '00' in PDTIME\n",
    "punches_df['PDTIME'] = pd.to_datetime(punches_df['PDTIME'], format='%d-%b-%y %H:%M:%S').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Sort punches_df based on TOKEN, PDTIME, MODE\n",
    "punches_df.sort_values(by=['TOKEN', 'PDTIME', 'MODE'], inplace=True)\n",
    "\n",
    "# Initialize result DataFrame with dynamic column names\n",
    "result_df = pd.DataFrame(columns=['TOKEN', 'PDATE', 'INTIME', \n",
    "                                  'OUTTIME'])\n",
    "\n",
    "in_punch_time = None\n",
    "out_punch_time = None\n",
    "\n",
    "# Iterate through punches_df to process punch data\n",
    "for index, row in punches_df.iterrows():\n",
    "    if row['MODE'] == 0:\n",
    "        in_punch_time = pd.to_datetime(row['PDTIME']).replace(second=0)\n",
    "    elif row['MODE'] == 1:\n",
    "        out_punch_time = pd.to_datetime(row['PDTIME']).replace(second=0)\n",
    "        if in_punch_time is not None:\n",
    "            time_difference = out_punch_time - in_punch_time\n",
    "            if time_difference.total_seconds() > 0:\n",
    "                hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "                minutes, seconds = divmod(remainder, 60)\n",
    "                \n",
    "                # Check for duplicates based on 'PDATE' and 'TOKEN'\n",
    "                duplicates = result_df[(result_df['PDATE'] == in_punch_time.strftime('%Y-%m-%d')) & (result_df['TOKEN'] == row['TOKEN'])]\n",
    "                \n",
    "                if duplicates.empty:\n",
    "                    # No duplicates, add a new row\n",
    "                    result_df = pd.concat([result_df, pd.DataFrame({\n",
    "                        'TOKEN': [row['TOKEN']],\n",
    "                        'PDATE': [in_punch_time.strftime('%Y-%m-%d')],\n",
    "                        'INTIME': [in_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                        'OUTTIME': [out_punch_time.strftime('%Y-%m-%d %H:%M:%S')]\n",
    "                    })], ignore_index=True)\n",
    "                else:\n",
    "                    # Duplicates found, update the existing row\n",
    "                    num_pairs = sum([col.startswith('INTIME') for col in duplicates.columns]) + 1\n",
    "                    \n",
    "                    # Add additional columns for each in and out punch pair dynamically\n",
    "                    result_df = pd.concat([result_df, pd.DataFrame({\n",
    "                        f'INTIME{num_pairs}': [in_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                        f'OUTTIME{num_pairs}': [out_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                    })], axis=1)\n",
    "                    \n",
    "                    \n",
    "\n",
    "# Sort result_df based on TOKEN, PDATE\n",
    "result_df = result_df.sort_values(by=['TOKEN', 'PDATE'])\n",
    "\n",
    "# Save the result to a CSV file\n",
    "result_df.to_csv('./6thJan_punches_modified.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "import numpy as np\n",
    "\n",
    "# Load and process punches data\n",
    "punches_table = DBF('D:/ZIONtest/punches.dbf', load=True)\n",
    "punches_df = pd.DataFrame(iter(punches_table))\n",
    "punches_df = punches_df.sort_values(by=['TOKEN', 'PDATE', 'MODE'])\n",
    "\n",
    "# Make seconds part '00' in PDTIME\n",
    "punches_df['PDTIME'] = pd.to_datetime(punches_df['PDTIME'], format='%d-%b-%y %H:%M:%S').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Sort punches_df based on TOKEN, PDTIME, MODE\n",
    "punches_df.sort_values(by=['TOKEN', 'PDTIME', 'MODE'], inplace=True)\n",
    "\n",
    "# Initialize result DataFrame with dynamic column names\n",
    "result_df = pd.DataFrame(columns=['TOKEN', 'PDATE', 'INTIME', \n",
    "                                  'OUTTIME'])\n",
    "\n",
    "in_punch_time = None\n",
    "out_punch_time = None\n",
    "\n",
    "# Iterate through punches_df to process punch data\n",
    "for index, row in punches_df.iterrows():\n",
    "    if row['MODE'] == 0:\n",
    "        in_punch_time = pd.to_datetime(row['PDTIME']).replace(second=0)\n",
    "    elif row['MODE'] == 1:\n",
    "        out_punch_time = pd.to_datetime(row['PDTIME']).replace(second=0)\n",
    "        if in_punch_time is not None:\n",
    "            time_difference = out_punch_time - in_punch_time\n",
    "            if time_difference.total_seconds() > 0:\n",
    "                hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "                minutes, seconds = divmod(remainder, 60)\n",
    "                \n",
    "                # Check for duplicates based on 'PDATE' and 'TOKEN'\n",
    "                duplicates = result_df[(result_df['PDATE'] == in_punch_time.strftime('%Y-%m-%d')) & (result_df['TOKEN'] == row['TOKEN'])]\n",
    "                \n",
    "                if duplicates.empty:\n",
    "                    # No duplicates, add a new row\n",
    "                    result_df = pd.concat([result_df, pd.DataFrame({\n",
    "                        'TOKEN': [row['TOKEN']],\n",
    "                        'PDATE': [in_punch_time.strftime('%Y-%m-%d')],\n",
    "                        'INTIME': [in_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                        'OUTTIME': [out_punch_time.strftime('%Y-%m-%d %H:%M:%S')]\n",
    "                    })], ignore_index=True)\n",
    "                else:\n",
    "                    # Duplicates found, update the existing row\n",
    "                    num_pairs = sum([col.startswith('INTIME') for col in duplicates.columns]) + 1\n",
    "                    \n",
    "                    # Add additional columns for each in and out punch pair dynamically\n",
    "                    result_df = pd.concat([result_df, pd.DataFrame({\n",
    "                        f'INTIME{num_pairs}': [in_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                        f'OUTTIME{num_pairs}': [out_punch_time.strftime('%Y-%m-%d %H:%M:%S')],\n",
    "                    })], axis=1)\n",
    "                    \n",
    "                    \n",
    "\n",
    "# Sort result_df based on TOKEN, PDATE\n",
    "result_df = result_df.sort_values(by=['TOKEN', 'PDATE'])\n",
    "\n",
    "# Save the result to a CSV file\n",
    "result_df.to_csv('./6thJan_punches_modified.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "import numpy as np\n",
    "\n",
    "# Load and process muster data\n",
    "muster_table = DBF('D:/ZIONtest/muster.dbf', load=True)\n",
    "muster_df = pd.DataFrame(iter(muster_table))\n",
    "muster_df = muster_df[['TOKEN', 'COMCODE', 'NAME', 'EMPCODE', 'EMP_DEPT', 'DEPT_NAME', 'EMP_DESI', 'DESI_NAME']]\n",
    "muster_df = muster_df.sort_values(by=['EMPCODE'])\n",
    "\n",
    "# Load and process punches data\n",
    "punches_table = DBF('D:/ZIONtest/punches.dbf', load=True)\n",
    "punches_df = pd.DataFrame(iter(punches_table))\n",
    "punches_df = punches_df.sort_values(by=['TOKEN', 'PDATE', 'MODE'])\n",
    "\n",
    "# Make seconds part '00' in PDTIME\n",
    "punches_df['PDTIME'] = pd.to_datetime(punches_df['PDTIME'], format='%d-%b-%y %H:%M:%S').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Sort punches_df based on TOKEN, PDTIME, MODE\n",
    "punches_df.sort_values(by=['TOKEN', 'PDTIME', 'MODE'], inplace=True)\n",
    "\n",
    "# Initialize result DataFrame\n",
    "result_df = pd.DataFrame(columns=['TOKEN', 'PDATE', 'INTIME', 'OUTTIME', 'INTIME1', 'OUTTIME1', 'TOTALTIME'])\n",
    "\n",
    "in_punch_time = None\n",
    "out_punch_time = None\n",
    "\n",
    "# Iterate through punches_df to process punch data\n",
    "for index, row in punches_df.iterrows():\n",
    "    if row['MODE'] == 0:\n",
    "        in_punch_time = pd.to_datetime(row['PDTIME']).replace(second=0)\n",
    "    elif row['MODE'] == 1:\n",
    "        out_punch_time = pd.to_datetime(row['PDTIME']).replace(second=0)\n",
    "        if in_punch_time is not None:\n",
    "            time_difference = out_punch_time - in_punch_time\n",
    "            if time_difference.total_seconds() > 0:\n",
    "                hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "                minutes, seconds = divmod(remainder, 60)\n",
    "                \n",
    "                # Check for duplicates based on 'PDATE' and 'TOKEN'\n",
    "                duplicates = result_df[(result_df['PDATE'] == in_punch_time.strftime('%Y-%m-%d')) & (result_df['TOKEN'] == row['TOKEN'])]\n",
    "                \n",
    "                if duplicates.empty:\n",
    "                    # No duplicates, add a new row\n",
    "                    result_df = pd.concat([result_df, pd.DataFrame({\n",
    "                        'TOKEN': [row['TOKEN']],\n",
    "                        'INTIME': [in_punch_time.strftime('%Y-%m-%d %H:%M')],\n",
    "                        'OUTTIME': [out_punch_time.strftime('%Y-%m-%d %H:%M')],\n",
    "                        'PDATE': [in_punch_time.strftime('%Y-%m-%d')],\n",
    "                        'INTIME1': [np.nan],\n",
    "                        'OUTTIME1': [np.nan],\n",
    "                        'TOTALTIME': [f'{hours:02}:{minutes:02}']\n",
    "                    })], ignore_index=True)\n",
    "                else:\n",
    "                    # Duplicates found, update the existing row\n",
    "                    result_df.loc[duplicates.index[-1], 'INTIME1'] = in_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                    result_df.loc[duplicates.index[-1], 'OUTTIME1'] = out_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                    \n",
    "                    # Calculate TOTALTIME based on the sum of time differences for both pairs\n",
    "                    total_time_difference_1 = pd.to_datetime(result_df.loc[duplicates.index[-1], 'OUTTIME']) - pd.to_datetime(result_df.loc[duplicates.index[-1], 'INTIME'])\n",
    "                    total_time_difference_2 = pd.to_datetime(result_df.loc[duplicates.index[-1], 'OUTTIME1']) - pd.to_datetime(result_df.loc[duplicates.index[-1], 'INTIME1'])\n",
    "                    \n",
    "                    total_time_difference = total_time_difference_1 + total_time_difference_2\n",
    "                    \n",
    "                    total_hours, total_remainder = divmod(total_time_difference.seconds, 3600)\n",
    "                    total_minutes, _ = divmod(total_remainder, 60)\n",
    "                    \n",
    "                    result_df.loc[duplicates.index[-1], 'TOTALTIME'] = f'{total_hours:02}:{total_minutes:02}'\n",
    "\n",
    "# Sort result_df based on TOKEN, PDATE\n",
    "result_df = result_df.sort_values(by=['TOKEN', 'PDATE'])\n",
    "\n",
    "# Save the result to a CSV file\n",
    "result_df.to_csv('./6thJan_punches_modified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "import numpy as np\n",
    "\n",
    "# Load and process muster data\n",
    "muster_table = DBF('D:/ZIONtest/muster.dbf', load=True)\n",
    "muster_df = pd.DataFrame(iter(muster_table))\n",
    "muster_df = muster_df[['TOKEN', 'COMCODE', 'NAME', 'EMPCODE', 'EMP_DEPT', 'DEPT_NAME', 'EMP_DESI', 'DESI_NAME']]\n",
    "muster_df = muster_df.sort_values(by=['EMPCODE'])\n",
    "\n",
    "# Load and process punches data\n",
    "punches_table = DBF('D:/ZIONtest/punches.dbf', load=True)\n",
    "punches_df = pd.DataFrame(iter(punches_table))\n",
    "punches_df = punches_df.sort_values(by=['TOKEN', 'PDATE', 'MODE'])\n",
    "\n",
    "# Make seconds part '00' in PDTIME\n",
    "punches_df['PDTIME'] = pd.to_datetime(punches_df['PDTIME'], format='%d-%b-%y %H:%M:%S').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Sort punches_df based on TOKEN, PDTIME, MODE\n",
    "punches_df.sort_values(by=['TOKEN', 'PDTIME', 'MODE'], inplace=True)\n",
    "\n",
    "# Initialize result DataFrame\n",
    "result_df = pd.DataFrame(columns=['TOKEN', 'PDATE', 'INTIME', 'OUTTIME', 'INTIME1', 'OUTTIME1', 'INTIME2', 'OUTTIME2', 'INTIME3', 'OUTTIME3','TOTALTIME'])\n",
    "\n",
    "in_punch_time = None\n",
    "out_punch_time = None\n",
    "\n",
    "# Iterate through punches_df to process punch data\n",
    "for index, row in punches_df.iterrows():\n",
    "    if row['MODE'] == 0:\n",
    "        in_punch_time = pd.to_datetime(row['PDTIME']).replace(second=0)\n",
    "    elif row['MODE'] == 1:\n",
    "        out_punch_time = pd.to_datetime(row['PDTIME']).replace(second=0)\n",
    "        if in_punch_time is not None:\n",
    "            time_difference = out_punch_time - in_punch_time\n",
    "            if time_difference.total_seconds() > 0:\n",
    "                hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "                minutes, seconds = divmod(remainder, 60)\n",
    "                \n",
    "                # Check for duplicates based on 'PDATE' and 'TOKEN'\n",
    "                duplicates = result_df[(result_df['PDATE'] == in_punch_time.strftime('%Y-%m-%d')) & (result_df['TOKEN'] == row['TOKEN'])]\n",
    "                \n",
    "                if duplicates.empty:\n",
    "                    # No duplicates, add a new row\n",
    "                    result_df = pd.concat([result_df, pd.DataFrame({\n",
    "                        'TOKEN': [row['TOKEN']],\n",
    "                        'INTIME': [in_punch_time.strftime('%Y-%m-%d %H:%M')],\n",
    "                        'OUTTIME': [out_punch_time.strftime('%Y-%m-%d %H:%M')],\n",
    "                        'PDATE': [in_punch_time.strftime('%Y-%m-%d')],\n",
    "                        'INTIME1': [np.nan],\n",
    "                        'OUTTIME1': [np.nan],\n",
    "                        'INTIME2': [np.nan],\n",
    "                        'OUTTIME2': [np.nan],\n",
    "                        'INTIME3': [np.nan],\n",
    "                        'OUTTIME3': [np.nan],\n",
    "                        'TOTALTIME': [f'{hours:02}:{minutes:02}']\n",
    "                    })], ignore_index=True)\n",
    "                else:\n",
    "                    # Duplicates found, update the existing row\n",
    "                    if pd.isna(result_df.loc[duplicates.index[-1], 'INTIME1']):\n",
    "                        result_df.loc[duplicates.index[-1], 'INTIME1'] = in_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                        result_df.loc[duplicates.index[-1], 'OUTTIME1'] = out_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                    elif pd.isna(result_df.loc[duplicates.index[-1], 'INTIME2']):\n",
    "                        result_df.loc[duplicates.index[-1], 'INTIME2'] = in_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                        result_df.loc[duplicates.index[-1], 'OUTTIME2'] = out_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                    elif pd.isna(result_df.loc[duplicates.index[-1], 'INTIME3']):\n",
    "                        result_df.loc[duplicates.index[-1], 'INTIME3'] = in_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                        result_df.loc[duplicates.index[-1], 'OUTTIME3'] = out_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                    else:\n",
    "                        # If INTIME1, OUTTIME1, INTIME2, OUTTIME2, INTIME3, and OUTTIME3 are not NaN, update them\n",
    "                        result_df.loc[duplicates.index[-1], 'INTIME1'] = in_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                        result_df.loc[duplicates.index[-1], 'OUTTIME1'] = out_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                        \n",
    "                        result_df.loc[duplicates.index[-1], 'INTIME2'] = in_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                        result_df.loc[duplicates.index[-1], 'OUTTIME2'] = out_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                        \n",
    "                        result_df.loc[duplicates.index[-1], 'INTIME3'] = in_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                        result_df.loc[duplicates.index[-1], 'OUTTIME3'] = out_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                    \n",
    "                    # Calculate TOTALTIME based on the sum of time differences for all pairs\n",
    "\n",
    "                    total_time_difference_1 = pd.to_datetime(result_df.loc[duplicates.index[-1], 'OUTTIME']) - pd.to_datetime(result_df.loc[duplicates.index[-1], 'INTIME'])\n",
    "                    total_time_difference_2 = pd.to_datetime(result_df.loc[duplicates.index[-1], 'OUTTIME1']) - pd.to_datetime(result_df.loc[duplicates.index[-1], 'INTIME1'])\n",
    "                    total_time_difference_3 = pd.to_datetime(result_df.loc[duplicates.index[-1], 'OUTTIME2']) - pd.to_datetime(result_df.loc[duplicates.index[-1], 'INTIME2'])\n",
    "                    total_time_difference_4 = pd.to_datetime(result_df.loc[duplicates.index[-1], 'OUTTIME3']) - pd.to_datetime(result_df.loc[duplicates.index[-1], 'INTIME3'])\n",
    "                    \n",
    "                    # Sum only non-NaN values of type pd.Timedelta\n",
    "                    total_time_difference = pd.to_timedelta(0)\n",
    "\n",
    "                    if isinstance(total_time_difference_1, pd.Timedelta):\n",
    "                        total_time_difference += total_time_difference_1\n",
    "\n",
    "                    if isinstance(total_time_difference_2, pd.Timedelta):\n",
    "                        total_time_difference += total_time_difference_2\n",
    "\n",
    "                    if isinstance(total_time_difference_3, pd.Timedelta):\n",
    "                        total_time_difference += total_time_difference_3\n",
    "\n",
    "                    if isinstance(total_time_difference_4, pd.Timedelta):\n",
    "                        total_time_difference += total_time_difference_4\n",
    "\n",
    "                    # Calculate hours and minutes\n",
    "                    total_hours, total_remainder = divmod(total_time_difference.seconds, 3600)\n",
    "                    total_minutes, _ = divmod(total_remainder, 60)\n",
    "\n",
    "                    result_df.loc[duplicates.index[-1], 'TOTALTIME'] = f'{total_hours:02}:{total_minutes:02}'\n",
    "\n",
    "# Sort result_df based on TOKEN, PDATE\n",
    "result_df = result_df.sort_values(by=['TOKEN', 'PDATE'])\n",
    "\n",
    "# Save the result to a CSV file\n",
    "result_df.to_csv('./6thJan_punches_modified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "import numpy as np\n",
    "\n",
    "# Load and process muster data\n",
    "muster_table = DBF('D:/ZIONtest/muster.dbf', load=True)\n",
    "muster_df = pd.DataFrame(iter(muster_table))\n",
    "muster_df = muster_df[['TOKEN', 'COMCODE', 'NAME', 'EMPCODE', 'EMP_DEPT', 'DEPT_NAME', 'EMP_DESI', 'DESI_NAME']]\n",
    "muster_df = muster_df.sort_values(by=['TOKEN'])\n",
    "\n",
    "# Load and process punches data\n",
    "punches_table = DBF('D:/ZIONtest/punches.dbf', load=True)\n",
    "punches_df = pd.DataFrame(iter(punches_table))\n",
    "\n",
    "punches_df['PDTIME'] = pd.to_datetime(punches_df['PDTIME'], format='%d-%b-%y %H:%M:%S').dt.strftime('%Y-%m-%d %H:%M:00')\n",
    "\n",
    "# Sort punches_df based on TOKEN, PDTIME, MODE\n",
    "punches_df.sort_values(by=['TOKEN', 'PDTIME', 'MODE'], inplace=True)\n",
    "\n",
    "# Initialize result DataFrame\n",
    "punch_df = pd.DataFrame(columns=['TOKEN', 'PDATE', 'INTIME1', 'OUTTIME1', 'INTIME2', 'OUTTIME2', 'INTIME3', 'OUTTIME3', 'INTIME4', 'OUTTIME4','INTIME', 'OUTTIME','TOTALTIME', 'STATUS','REMARKS'])\n",
    "\n",
    "in_punch_time = None\n",
    "out_punch_time = None\n",
    "\n",
    "# Iterate through punches_df to process punch data\n",
    "for index, row in punches_df.iterrows():\n",
    "    if row['MODE'] == 0:\n",
    "        in_punch_time = pd.to_datetime(row['PDTIME']).replace(second=0)\n",
    "    elif row['MODE'] == 1:\n",
    "        out_punch_time = pd.to_datetime(row['PDTIME']).replace(second=0)\n",
    "        if in_punch_time is not None:\n",
    "            time_difference = out_punch_time - in_punch_time\n",
    "            if time_difference.total_seconds() > 0:\n",
    "                hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "                minutes, seconds = divmod(remainder, 60)\n",
    "                \n",
    "                # Check for duplicates based on 'PDATE' and 'TOKEN'\n",
    "                duplicates = punch_df[(punch_df['PDATE'] == in_punch_time.strftime('%Y-%m-%d')) & (punch_df['TOKEN'] == row['TOKEN'])]\n",
    "                \n",
    "                if duplicates.empty:\n",
    "                    # No duplicates, add a new row\n",
    "                    punch_df = pd.concat([punch_df, pd.DataFrame({\n",
    "                        'TOKEN': [row['TOKEN']],\n",
    "                        'PDATE': [in_punch_time.strftime('%Y-%m-%d')],\n",
    "                        'INTIME1': [in_punch_time.strftime('%Y-%m-%d %H:%M')],\n",
    "                        'OUTTIME1': [out_punch_time.strftime('%Y-%m-%d %H:%M')],\n",
    "                        'INTIME2': [np.nan],\n",
    "                        'OUTTIME2': [np.nan],\n",
    "                        'INTIME3': [np.nan],\n",
    "                        'OUTTIME3': [np.nan],\n",
    "                        'INTIME4': [np.nan],\n",
    "                        'OUTTIME4': [np.nan],\n",
    "                        'INTIME': [in_punch_time.strftime('%Y-%m-%d %H:%M')],\n",
    "                        'OUTTIME': [out_punch_time.strftime('%Y-%m-%d %H:%M')],\n",
    "                        'TOTALTIME': [f'{hours:02}:{minutes:02}'], # Make seconds part '00' in PDTIME\n",
    "                        'REMARKS': \"\"\n",
    "                    })], ignore_index=True)\n",
    "\n",
    "                    # result_df.loc['STATUS'] = \"PR\"\n",
    "                else:\n",
    "                    # Duplicates found, update the existing row\n",
    "                    if pd.isna(punch_df.loc[duplicates.index[-1], 'INTIME2']):\n",
    "                        punch_df.loc[duplicates.index[-1], 'INTIME2'] = in_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                        punch_df.loc[duplicates.index[-1], 'OUTTIME2'] = out_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                    elif pd.isna(punch_df.loc[duplicates.index[-1], 'INTIME3']):\n",
    "                        punch_df.loc[duplicates.index[-1], 'INTIME3'] = in_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                        punch_df.loc[duplicates.index[-1], 'OUTTIME3'] = out_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                    elif pd.isna(punch_df.loc[duplicates.index[-1], 'INTIME4']):\n",
    "                        punch_df.loc[duplicates.index[-1], 'INTIME4'] = in_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "                        punch_df.loc[duplicates.index[-1], 'OUTTIME4'] = out_punch_time.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "                    # update REMARKS for multiple punches\n",
    "                    punch_df.loc[duplicates.index[-1], 'REMARKS'] = \"*\"\n",
    "                    \n",
    "                    # Update OUTTIME4\n",
    "                    punch_df.loc[duplicates.index[-1], 'OUTTIME'] = out_punch_time.strftime('%Y-%m-%d %H:%M') if not pd.isna(out_punch_time) else np.nan\n",
    "\n",
    "\n",
    "                    # Calculate TOTALTIME based on the sum of time differences for all pairs\n",
    "                    total_time_difference_1 = pd.to_datetime(punch_df.loc[duplicates.index[-1], 'OUTTIME1']) - pd.to_datetime(punch_df.loc[duplicates.index[-1], 'INTIME1'])\n",
    "                    total_time_difference_2 = pd.to_datetime(punch_df.loc[duplicates.index[-1], 'OUTTIME2']) - pd.to_datetime(punch_df.loc[duplicates.index[-1], 'INTIME2'])\n",
    "                    total_time_difference_3 = pd.to_datetime(punch_df.loc[duplicates.index[-1], 'OUTTIME3']) - pd.to_datetime(punch_df.loc[duplicates.index[-1], 'INTIME3'])\n",
    "                    total_time_difference_4 = pd.to_datetime(punch_df.loc[duplicates.index[-1], 'OUTTIME4']) - pd.to_datetime(punch_df.loc[duplicates.index[-1], 'INTIME4'])\n",
    "                    \n",
    "                    # Sum only non-NaN values of type pd.Timedelta\n",
    "                    total_time_difference = pd.to_timedelta(0)\n",
    "\n",
    "                    if isinstance(total_time_difference_1, pd.Timedelta):\n",
    "                        total_time_difference += total_time_difference_1\n",
    "\n",
    "                    if isinstance(total_time_difference_2, pd.Timedelta):\n",
    "                        total_time_difference += total_time_difference_2\n",
    "\n",
    "                    if isinstance(total_time_difference_3, pd.Timedelta):\n",
    "                        total_time_difference += total_time_difference_3\n",
    "\n",
    "                    if isinstance(total_time_difference_4, pd.Timedelta):\n",
    "                        total_time_difference += total_time_difference_4\n",
    "\n",
    "                    # Calculate hours and minutes\n",
    "                    total_hours, total_remainder = divmod(total_time_difference.seconds, 3600)\n",
    "                    total_minutes, _ = divmod(total_remainder, 60)\n",
    "\n",
    "                    punch_df.loc[duplicates.index[-1], 'TOTALTIME'] = f'{total_hours:02}:{total_minutes:02}'\n",
    "\n",
    "# Sort result_df based on TOKEN, PDATE\n",
    "punch_df = punch_df.sort_values(by=['TOKEN', 'PDATE'])\n",
    "\n",
    "muster_punch_df = pd.merge(muster_df, punch_df, on='TOKEN', how='left')\n",
    "\n",
    "# Save the result to a CSV file\n",
    "muster_punch_df.to_csv('./6thJan_punches_modified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dbfread import DBF\n",
    "\n",
    "dated_table = DBF('D:/ZIONtest/dated.dbf', load=True)\n",
    "start_date = dated_table.records[0]['MUFRDATE']\n",
    "end_date = dated_table.records[0]['MUTODATE']\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# Load and process muster data\n",
    "muster_table = DBF('D:/ZIONtest/muster.dbf', load=True)\n",
    "muster_df = pd.DataFrame(iter(muster_table))\n",
    "\n",
    "# Filter only active employees (where 'DEL' is False) and allow employees date leave within date range\n",
    "muster_df = muster_df[(muster_df['DEL'] == False) | (muster_df['DATE_LEAVE'] >= start_date) & (muster_df['DATE_LEAVE'] <= end_date)]\n",
    "\n",
    "muster_df = muster_df[['TOKEN', 'COMCODE', 'NAME', 'EMPCODE', 'EMP_DEPT', 'DEPT_NAME', 'EMP_DESI', 'DESI_NAME', 'DATE_JOIN', 'DATE_LEAVE']]\n",
    "muster_df = muster_df.sort_values(by=['TOKEN'])\n",
    "muster_df.to_csv('17thJan.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "\n",
    "# Load dated data\n",
    "dated_table = DBF('D:/ZIONtest/dated.dbf', load=True)\n",
    "start_date = dated_table.records[0]['MUFRDATE']\n",
    "end_date = dated_table.records[0]['MUTODATE']\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "# Load and process muster data\n",
    "muster_table = DBF('D:/ZIONtest/muster.dbf', load=True)\n",
    "muster_df = pd.DataFrame(iter(muster_table))\n",
    "\n",
    "# Filter only active employees (where 'DEL' is False) and allow employees date leave within date range\n",
    "muster_df = muster_df[(muster_df['DEL'] == False) | ((muster_df['DATE_LEAVE'] >= start_date) & (muster_df['DATE_LEAVE'] <= end_date))]\n",
    "\n",
    "muster_df = muster_df[['TOKEN', 'COMCODE', 'NAME', 'EMPCODE', 'EMP_DEPT', 'DEPT_NAME', 'EMP_DESI', 'DESI_NAME', 'DATE_JOIN', 'DATE_LEAVE']]\n",
    "muster_df = muster_df.sort_values(by=['TOKEN'])\n",
    "\n",
    "# Create a new DataFrame to store the expanded dates\n",
    "expanded_dates_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each row in muster_df\n",
    "for index, row in muster_df.iterrows():\n",
    "    # Extract relevant information\n",
    "    token = row['TOKEN']\n",
    "    \n",
    "    # Generate date range between start_date and end_date\n",
    "    date_range = pd.date_range(start_date_str, end_date_str, closed=None)\n",
    "    \n",
    "    # Create a DataFrame with repeated information for each date in the range\n",
    "    temp_df = pd.DataFrame({\n",
    "        'TOKEN': [token] * len(date_range),\n",
    "        'COMCODE': row['COMCODE'],\n",
    "        'NAME': row['NAME'],\n",
    "        'EMPCODE': row['EMPCODE'],\n",
    "        'EMP_DEPT': row['EMP_DEPT'],\n",
    "        'DEPT_NAME': row['DEPT_NAME'],\n",
    "        'EMP_DESI': row['EMP_DESI'],\n",
    "        'DESI_NAME': row['DESI_NAME'],\n",
    "        'DATE_JOIN': row['DATE_JOIN'],\n",
    "        'DATE_LEAVE': row['DATE_LEAVE'],\n",
    "        'PDATE': date_range,\n",
    "        \n",
    "    })\n",
    "\n",
    "    # Append the temporary DataFrame to the expanded_dates_df\n",
    "    expanded_dates_df = expanded_dates_df.append(temp_df, ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by TOKEN and PDATE\n",
    "expanded_dates_df = expanded_dates_df.sort_values(by=['TOKEN', 'PDATE'])\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "expanded_dates_df.to_csv('17thJan.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "2023-09-19\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "ok\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Of the four parameters: start, end, periods, and freq, exactly three must be specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-053a1b3382df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstart_date\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mdate_join\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ok'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mdate_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdate_join\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdate_leave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'not ok'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rak_t\\anaconda3\\envs\\vfp_python\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py\u001b[0m in \u001b[0;36mdate_range\u001b[1;34m(start, end, periods, freq, tz, normalize, name, closed, **kwargs)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m         \u001b[0mclosed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclosed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m     )\n\u001b[0;32m   1009\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rak_t\\anaconda3\\envs\\vfp_python\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36m_generate_range\u001b[1;34m(cls, start, end, periods, freq, tz, normalize, ambiguous, nonexistent, closed)\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_not_none\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiods\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             raise ValueError(\n\u001b[1;32m--> 365\u001b[1;33m                 \u001b[1;34m\"Of the four parameters: start, end, periods, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m                 \u001b[1;34m\"and freq, exactly three must be specified\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Of the four parameters: start, end, periods, and freq, exactly three must be specified"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "\n",
    "# Load dated data\n",
    "dated_table = DBF('D:/ZIONtest/dated.dbf', load=True)\n",
    "start_date = dated_table.records[0]['MUFRDATE']\n",
    "end_date = dated_table.records[0]['MUTODATE']\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "# Load and process muster data\n",
    "muster_table = DBF('D:/ZIONtest/muster.dbf', load=True)\n",
    "muster_df = pd.DataFrame(iter(muster_table))\n",
    "\n",
    "# Filter only active employees (where 'DEL' is False) and allow employees date leave within date range\n",
    "muster_df = muster_df[(muster_df['DEL'] == False) | ((muster_df['DATE_LEAVE'] >= start_date) & (muster_df['DATE_LEAVE'] <= end_date))]\n",
    "\n",
    "muster_df = muster_df[['TOKEN', 'COMCODE', 'NAME', 'EMPCODE', 'EMP_DEPT', 'DEPT_NAME', 'EMP_DESI', 'DESI_NAME', 'DATE_JOIN', 'DATE_LEAVE']]\n",
    "muster_df = muster_df.sort_values(by=['TOKEN'])\n",
    "\n",
    "# Create a new DataFrame to store the expanded dates\n",
    "expanded_dates_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each row in muster_df\n",
    "for index, row in muster_df.iterrows():\n",
    "    # Extract relevant information\n",
    "    token = row['TOKEN']\n",
    "    date_join = row['DATE_JOIN']\n",
    "    date_leave = row['DATE_LEAVE']\n",
    "\n",
    "# Check if DATE_JOIN is in the range of start_date and end_date\n",
    "if date_leave is None:\n",
    "        date_leave = datetime.now()\n",
    "if start_date <= date_join <= end_date:\n",
    "    date_range = pd.date_range(start=date_join, end=date_leave, closed=None)\n",
    "else:\n",
    "    date_range = pd.date_range(start=start_date_str, end=end_date_str, closed=None)\n",
    "\n",
    "    # Create a DataFrame with repeated information for each date in the range\n",
    "    temp_df = pd.DataFrame({\n",
    "        'TOKEN': [token] * len(date_range),\n",
    "        'COMCODE': row['COMCODE'],\n",
    "        'NAME': row['NAME'],\n",
    "        'EMPCODE': row['EMPCODE'],\n",
    "        'EMP_DEPT': row['EMP_DEPT'],\n",
    "        'DEPT_NAME': row['DEPT_NAME'],\n",
    "        'EMP_DESI': row['EMP_DESI'],\n",
    "        'DESI_NAME': row['DESI_NAME'],\n",
    "        'DATE_JOIN': row['DATE_JOIN'],\n",
    "        'DATE_LEAVE': row['DATE_LEAVE'],\n",
    "        'PDATE': date_range,\n",
    "    })\n",
    "\n",
    "    # Append the temporary DataFrame to the expanded_dates_df\n",
    "    expanded_dates_df = expanded_dates_df.append(temp_df, ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by TOKEN and PDATE\n",
    "expanded_dates_df = expanded_dates_df.sort_values(by=['TOKEN', 'PDATE'])\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "expanded_dates_df.to_csv('17thJan.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract token-wise weekly off days\n",
    "# Calculate the number of days between start_date and end_date\n",
    "#date_range = (end_date - start_date).days + 1\n",
    "# Generate the weekly off day columns for the specified date range\n",
    "#weekly_off_columns = [f'WO_{i}' for i in range(1, 31) for j in range(0, date_range, 7)]\n",
    "\n",
    "# Melt the DataFrame to have a 'Day' column representing the weekly off days\n",
    "#token_wise_weekly_off = pd.melt(token_wise_weekly_off, id_vars=['TOKEN'], var_name='Day', value_name='Weekly_Off')\n",
    "\n",
    "# Filter the columns based on the date range\n",
    "#filtered_weekly_off_columns = weekly_off_columns[:date_range]\n",
    "\n",
    "#print(filtered_weekly_off_columns)\n",
    "\n",
    "##########################################\n",
    "#weekly_off_columns = [f'WO_{i}' for i in range(1, 31)]  # Assuming you have 'WO_1' to 'WO_30' columns\n",
    "#token_wise_weekly_off = muster_df[['TOKEN'] + weekly_off_columns].copy()\n",
    "\n",
    "# Melt the DataFrame to have a 'Day' column representing the weekly off days\n",
    "#token_wise_weekly_off = pd.melt(token_wise_weekly_off, id_vars=['TOKEN'], var_name='Day', value_name='Weekly_Off')\n",
    "\n",
    "# Filter only logically true days (Weekly_Off == True)\n",
    "#token_wise_weekly_off = token_wise_weekly_off[token_wise_weekly_off['Weekly_Off'] == True]\n",
    "\n",
    "# If 'Day' column contains 'WO_', remove it to have just the numeric day\n",
    "#token_wise_weekly_off['Day'] = token_wise_weekly_off['Day'].str.replace('WO_', '').astype(int)\n",
    "\n",
    "# Print or use the resulting DataFrame as needed\n",
    "#print(token_wise_weekly_off[['TOKEN', 'Day']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WO_1   WO_2   WO_3   WO_4   WO_5   WO_6   WO_7   WO_8   WO_9  WO_10  ...  \\\n",
      "0  False  False  False   True  False  False  False  False  False  False  ...   \n",
      "1  False  False  False  False   True  False  False  False  False  False  ...   \n",
      "2  False  False  False  False  False   True  False  False  False  False  ...   \n",
      "3  False  False  False  False  False  False   True  False  False  False  ...   \n",
      "4   True  False  False  False  False  False  False   True  False  False  ...   \n",
      "6  False  False   True  False  False  False  False  False  False   True  ...   \n",
      "7  False  False   True  False  False  False  False  False  False   True  ...   \n",
      "8  False  False   True  False  False  False  False  False  False   True  ...   \n",
      "\n",
      "   WO_21  WO_22  WO_23  WO_24  WO_25  WO_26  WO_27  WO_28  WO_29  WO_30  \n",
      "0  False  False  False  False   True  False  False  False  False  False  \n",
      "1  False  False  False  False  False   True  False  False  False  False  \n",
      "2  False  False  False  False  False  False   True  False  False  False  \n",
      "3   True  False  False  False  False  False  False   True  False  False  \n",
      "4  False   True  False  False  False  False  False  False   True  False  \n",
      "6  False  False  False   True  False  False  False  False  False  False  \n",
      "7  False  False  False   True  False  False  False  False  False  False  \n",
      "8  False  False  False   True  False  False  False  False  False  False  \n",
      "\n",
      "[8 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "\n",
    "# Load dated data\n",
    "dated_table = DBF('D:/ZIONtest/dated.dbf', load=True)\n",
    "start_date = dated_table.records[0]['MUFRDATE']\n",
    "end_date = dated_table.records[0]['MUTODATE']\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "\n",
    "muster_table = DBF('D:/ZIONtest/muster.dbf', load=True)\n",
    "muster_df = pd.DataFrame(iter(muster_table))\n",
    "\n",
    "# Filter only active employees (where 'DEL' is False) and allow employees to leave within the date range\n",
    "muster_df = muster_df[(muster_df['DEL'] == False) | ((muster_df['DATE_LEAVE'] >= start_date) & (muster_df['DATE_LEAVE'] <= end_date))]\n",
    "muster_df = muster_df.sort_values(by=['TOKEN'])\n",
    "\n",
    "# Extract month from start_date (assuming start_date is in datetime format)\n",
    "month = start_date.month\n",
    "\n",
    "# Create column names dynamically based on the month\n",
    "columns_to_select = [f'WO_{i}' for i in range(1, 31)]\n",
    "\n",
    "# Use loc to select the columns\n",
    "selected_columns = muster_df.loc[:, muster_df.columns.isin(columns_to_select)]\n",
    "\n",
    "print(selected_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       2023-09-01  2023-09-02  2023-09-03  2023-09-04  2023-09-05  2023-09-06  \\\n",
      "TOKEN                                                                           \n",
      "1           False       False       False        True       False       False   \n",
      "2           False       False       False       False        True       False   \n",
      "3           False       False       False       False       False        True   \n",
      "4           False       False       False       False       False       False   \n",
      "6            True       False       False       False       False       False   \n",
      "8           False       False        True       False       False       False   \n",
      "9           False       False        True       False       False       False   \n",
      "10          False       False        True       False       False       False   \n",
      "\n",
      "       2023-09-07  2023-09-08  2023-09-09  2023-09-10  ...  2023-09-21  \\\n",
      "TOKEN                                                  ...               \n",
      "1           False       False       False       False  ...       False   \n",
      "2           False       False       False       False  ...       False   \n",
      "3           False       False       False       False  ...       False   \n",
      "4            True       False       False       False  ...        True   \n",
      "6           False        True       False       False  ...       False   \n",
      "8           False       False       False        True  ...       False   \n",
      "9           False       False       False        True  ...       False   \n",
      "10          False       False       False        True  ...       False   \n",
      "\n",
      "       2023-09-22  2023-09-23  2023-09-24  2023-09-25  2023-09-26  2023-09-27  \\\n",
      "TOKEN                                                                           \n",
      "1           False       False       False        True       False       False   \n",
      "2           False       False       False       False        True       False   \n",
      "3           False       False       False       False       False        True   \n",
      "4           False       False       False       False       False       False   \n",
      "6            True       False       False       False       False       False   \n",
      "8           False       False        True       False       False       False   \n",
      "9           False       False        True       False       False       False   \n",
      "10          False       False        True       False       False       False   \n",
      "\n",
      "       2023-09-28  2023-09-29  2023-09-30  \n",
      "TOKEN                                      \n",
      "1           False       False       False  \n",
      "2           False       False       False  \n",
      "3           False       False       False  \n",
      "4            True       False       False  \n",
      "6           False        True       False  \n",
      "8           False       False       False  \n",
      "9           False       False       False  \n",
      "10          False       False       False  \n",
      "\n",
      "[8 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "\n",
    "# Load dated data\n",
    "dated_table = DBF('D:/ZIONtest/dated.dbf', load=True)\n",
    "start_date = dated_table.records[0]['MUFRDATE']\n",
    "end_date = dated_table.records[0]['MUTODATE']\n",
    "\n",
    "muster_table = DBF('D:/ZIONtest/muster.dbf', load=True)\n",
    "muster_df = pd.DataFrame(iter(muster_table))\n",
    "\n",
    "# Filter only active employees (where 'DEL' is False) and allow employees to leave within the date range\n",
    "muster_df = muster_df[(muster_df['DEL'] == False) | ((muster_df['DATE_LEAVE'] >= start_date) & (muster_df['DATE_LEAVE'] <= end_date))]\n",
    "muster_df = muster_df.sort_values(by=['TOKEN'])\n",
    "\n",
    "# Generate date range between start_date and end_date\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Map date strings to corresponding column names\n",
    "column_date_mapping = {f'WO_{i}': date.strftime('%Y-%m-%d') for i, date in enumerate(date_range, start=1)}\n",
    "\n",
    "# Use loc to select the columns based on the mapped dates\n",
    "selected_columns = muster_df.loc[:, column_date_mapping.keys()]\n",
    "\n",
    "# Rename the columns to match the mapped dates\n",
    "selected_columns.columns = [column_date_mapping[col] for col in selected_columns.columns]\n",
    "\n",
    "selected_columns.index = muster_df['TOKEN']\n",
    "print(selected_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 1: ['2023-09-04', '2023-09-11', '2023-09-18', '2023-09-25']\n",
      "Token 2: ['2023-09-05', '2023-09-12', '2023-09-19', '2023-09-26']\n",
      "Token 3: ['2023-09-06', '2023-09-13', '2023-09-20', '2023-09-27']\n",
      "Token 4: ['2023-09-07', '2023-09-14', '2023-09-21', '2023-09-28']\n",
      "Token 6: ['2023-09-01', '2023-09-08', '2023-09-15', '2023-09-22', '2023-09-29']\n",
      "Token 8: ['2023-09-03', '2023-09-10', '2023-09-17', '2023-09-24']\n",
      "Token 9: ['2023-09-03', '2023-09-10', '2023-09-17', '2023-09-24']\n",
      "Token 10: ['2023-09-03', '2023-09-10', '2023-09-17', '2023-09-24']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "\n",
    "# Load dated data\n",
    "dated_table = DBF('D:/ZIONtest/dated.dbf', load=True)\n",
    "start_date = dated_table.records[0]['MUFRDATE']\n",
    "end_date = dated_table.records[0]['MUTODATE']\n",
    "\n",
    "muster_table = DBF('D:/ZIONtest/muster.dbf', load=True)\n",
    "muster_df = pd.DataFrame(iter(muster_table))\n",
    "\n",
    "# Filter only active employees (where 'DEL' is False) and allow employees to leave within the date range\n",
    "muster_df = muster_df[(muster_df['DEL'] == False) | ((muster_df['DATE_LEAVE'] >= start_date) & (muster_df['DATE_LEAVE'] <= end_date))]\n",
    "muster_df = muster_df.sort_values(by=['TOKEN'])\n",
    "\n",
    "# Generate date range between start_date and end_date\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Map date strings to corresponding column names\n",
    "column_date_mapping = {f'WO_{i}': date.strftime('%Y-%m-%d') for i, date in enumerate(date_range, start=1)}\n",
    "\n",
    "# Use loc to select the columns based on the mapped dates\n",
    "selected_columns = muster_df.loc[:, column_date_mapping.keys()]\n",
    "\n",
    "# Rename the columns to match the mapped dates\n",
    "selected_columns.columns = [column_date_mapping[col] for col in selected_columns.columns]\n",
    "\n",
    "selected_columns.index = muster_df['TOKEN']\n",
    "\n",
    "# Create an empty dictionary to store the results\n",
    "token_dates = {}\n",
    "\n",
    "# Iterate through each row of the DataFrame\n",
    "for index, row in selected_columns.iterrows():\n",
    "    # Get the token value\n",
    "    token = index\n",
    "    \n",
    "    # Get the dates where the value is True\n",
    "    true_dates = [col for col, value in row.items() if value]\n",
    "    \n",
    "    # Store the result in the dictionary\n",
    "    token_dates[token] = true_dates\n",
    "\n",
    "# Print the result\n",
    "for token, dates in token_dates.items():\n",
    "    print(f\"Token {token}: {dates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 1: ['2023-09-04', '2023-09-11', '2023-09-18', '2023-09-25']\n",
      "Token 2: ['2023-09-05', '2023-09-12', '2023-09-19', '2023-09-26']\n",
      "Token 3: ['2023-09-06', '2023-09-13', '2023-09-20', '2023-09-27']\n",
      "Token 4: ['2023-09-07', '2023-09-14', '2023-09-21', '2023-09-28']\n",
      "Token 6: ['2023-09-01', '2023-09-08', '2023-09-15', '2023-09-22', '2023-09-29']\n",
      "Token 8: ['2023-09-03', '2023-09-10', '2023-09-17', '2023-09-24']\n",
      "Token 9: ['2023-09-03', '2023-09-10', '2023-09-17', '2023-09-24']\n",
      "Token 10: ['2023-09-03', '2023-09-10', '2023-09-17', '2023-09-24']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "\n",
    "# Load dated data\n",
    "dated_table = DBF('D:/ZIONtest/dated.dbf', load=True)\n",
    "start_date = dated_table.records[0]['MUFRDATE']\n",
    "end_date = dated_table.records[0]['MUTODATE']\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "# Load holidays data and filter\n",
    "holidays_table = DBF('D:/ZIONtest/holmast.dbf', load=True)\n",
    "holidays_df = pd.DataFrame(holidays_table)\n",
    "filtered_holidays_df = holidays_df[(holidays_df['HOL_DT'] >= start_date) & (holidays_df['HOL_DT'] <= end_date)]\n",
    "\n",
    "# Load and process muster data\n",
    "muster_table = DBF('D:/ZIONtest/muster.dbf', load=True)\n",
    "muster_df = pd.DataFrame(iter(muster_table))\n",
    "# Filter only active employees (where 'DEL' is False) and allow employees date leave within date range\n",
    "muster_df = muster_df[(muster_df['DEL'] == False) | ((muster_df['DATE_LEAVE'] >= start_date) & (muster_df['DATE_LEAVE'] <= end_date))]\n",
    "muster_df = muster_df.sort_values(by=['TOKEN'])\n",
    "\n",
    "# Create a new DataFrame to store the expanded dates\n",
    "expanded_dates_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each row in muster_df\n",
    "for index, row in muster_df.iterrows():\n",
    "    # Extract relevant information\n",
    "    token = row['TOKEN']\n",
    "    date_join = row['DATE_JOIN']\n",
    "    date_leave = row['DATE_LEAVE']\n",
    "    \n",
    "    if start_date <= date_join <= end_date:\n",
    "        if date_leave is not None:\n",
    "            date_range = pd.date_range(date_join, date_leave, closed=None)\n",
    "        else:\n",
    "            date_range = pd.date_range(date_join, end_date_str, closed=None)\n",
    "    else:\n",
    "        date_range = pd.date_range(start_date_str, end_date_str, closed=None)\n",
    "\n",
    "    # Create a DataFrame with repeated information for each date in the range\n",
    "    temp_df = pd.DataFrame({\n",
    "        'TOKEN': [token] * len(date_range),\n",
    "        'COMCODE': row['COMCODE'],\n",
    "        'NAME': row['NAME'],\n",
    "        'EMPCODE': row['EMPCODE'],\n",
    "        'EMP_DEPT': row['EMP_DEPT'],\n",
    "        'DEPT_NAME': row['DEPT_NAME'],\n",
    "        'EMP_DESI': row['EMP_DESI'],\n",
    "        'DESI_NAME': row['DESI_NAME'],\n",
    "        'DATE_JOIN': row['DATE_JOIN'],\n",
    "        'DATE_LEAVE': row['DATE_LEAVE'],\n",
    "        'PDATE': date_range,\n",
    "        'ATT_STATUS': \"AB\",\n",
    "    })\n",
    "\n",
    "    # Append the temporary DataFrame to the expanded_dates_df\n",
    "    expanded_dates_df = expanded_dates_df.append(temp_df, ignore_index=True)\n",
    "\n",
    "# Update the 'ATT_STATUS' for corresponding holiday dates\n",
    "for index, row in filtered_holidays_df.iterrows():\n",
    "    holiday_date = row['HOL_DT']\n",
    "    hol_type = row['HOL_TYPE']\n",
    "    expanded_dates_df.loc[expanded_dates_df['PDATE'].dt.date == holiday_date, 'ATT_STATUS'] = hol_type\n",
    "\n",
    "# Set 'ATT_STATUS' to 'w/o' for the dates in token_dates, otherwise it will be 'AB'\n",
    "for token, dates in token_dates.items():\n",
    "    expanded_dates_df.loc[(expanded_dates_df['TOKEN'] == token) & (expanded_dates_df['PDATE'].dt.strftime('%Y-%m-%d').isin(dates)), 'ATT_STATUS'] = 'w/o'\n",
    "\n",
    "# Sort the DataFrame by TOKEN and PDATE\n",
    "expanded_dates_df = expanded_dates_df.sort_values(by=['TOKEN', 'PDATE'])\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "expanded_dates_df.to_csv('17thJan_new.csv', index=False)\n",
    "\n",
    "# Print the result\n",
    "for token, dates in token_dates.items():\n",
    "    print(f\"Token {token}: {dates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "\n",
    "# Load dated data\n",
    "dated_table = DBF('D:/ZIONtest/dated.dbf', load=True)\n",
    "start_date = dated_table.records[0]['MUFRDATE']\n",
    "end_date = dated_table.records[0]['MUTODATE']\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "# Load holidays data and filter\n",
    "holidays_table = DBF('D:/ZIONtest/holmast.dbf', load=True)\n",
    "holidays_df = pd.DataFrame(holidays_table)\n",
    "filtered_holidays_df = holidays_df[(holidays_df['HOL_DT'] >= start_date) & (holidays_df['HOL_DT'] <= end_date)]\n",
    "\n",
    "# Load and process muster data\n",
    "muster_table = DBF('D:/ZIONtest/muster.dbf', load=True)\n",
    "muster_df = pd.DataFrame(iter(muster_table))\n",
    "# Filter only active employees (where 'DEL' is False) and allow employees date leave within date range\n",
    "muster_df = muster_df[(muster_df['DEL'] == False) | ((muster_df['DATE_LEAVE'] >= start_date) & (muster_df['DATE_LEAVE'] <= end_date))]\n",
    "muster_df = muster_df.sort_values(by=['TOKEN'])\n",
    "\n",
    "# Create a new DataFrame to store the expanded dates\n",
    "expanded_dates_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each row in muster_df\n",
    "for index, row in muster_df.iterrows():\n",
    "    # Extract relevant information\n",
    "    token = row['TOKEN']\n",
    "    date_join = row['DATE_JOIN']\n",
    "    date_leave = row['DATE_LEAVE']\n",
    "    \n",
    "    if start_date <= date_join <= end_date:\n",
    "        if date_leave is not None:\n",
    "            date_range = pd.date_range(date_join, date_leave, closed=None)\n",
    "        else:\n",
    "            date_range = pd.date_range(date_join, end_date_str, closed=None)\n",
    "    else:\n",
    "        date_range = pd.date_range(start_date_str, end_date_str, closed=None)\n",
    "\n",
    "    # Create a DataFrame with repeated information for each date in the range\n",
    "    temp_df = pd.DataFrame({\n",
    "        'TOKEN': [token] * len(date_range),\n",
    "        'COMCODE': row['COMCODE'],\n",
    "        'NAME': row['NAME'],\n",
    "        'EMPCODE': row['EMPCODE'],\n",
    "        'EMP_DEPT': row['EMP_DEPT'],\n",
    "        'DEPT_NAME': row['DEPT_NAME'],\n",
    "        'EMP_DESI': row['EMP_DESI'],\n",
    "        'DESI_NAME': row['DESI_NAME'],\n",
    "        'DATE_JOIN': row['DATE_JOIN'],\n",
    "        'DATE_LEAVE': row['DATE_LEAVE'],\n",
    "        'PDATE': date_range,\n",
    "        'ATT_STATUS':\"AB\",\n",
    "    })\n",
    "\n",
    "    # Append the temporary DataFrame to the expanded_dates_df\n",
    "    expanded_dates_df = expanded_dates_df.append(temp_df, ignore_index=True)\n",
    "    \n",
    "# Update the 'ATT_STATUS' for corresponding holiday dates\n",
    "for index, row in filtered_holidays_df.iterrows():\n",
    "    holiday_date = row['HOL_DT']\n",
    "    hol_type = row['HOL_TYPE']\n",
    "    expanded_dates_df.loc[expanded_dates_df['PDATE'].dt.date == holiday_date, 'ATT_STATUS'] = hol_type\n",
    "\n",
    "# Sort the DataFrame by TOKEN and PDATE\n",
    "expanded_dates_df = expanded_dates_df.sort_values(by=['TOKEN', 'PDATE'])\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "expanded_dates_df.to_csv('17thJan.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vfp_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
